---
layout: post
title: "Two Open Problems for the Subgroup-Reduction based Dedekindian HSP Algorithm"
tags: maths cs
---

{% raw %}

  
<p>One of my main idea after having studied the Hidden Subgroup Problem is that subgroup simplification is likely to play an important role. Basically, rather than directly finding the hidden subgroup <math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>H</mi> </math> by working on the whole initial group <math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>G</mi> </math>, we only try to get partial information on <math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>H</mi> </math> in a first time. This information allows us to move to a simpler HSP problem and we can iterate this process until the complete determination of <math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>H</mi> </math>. Several reductions of this kind exist and I think the sophisticated solution to HSP over 2-nil groups illustrates well how this technique can be efficient.</p>

<p>Using only subgroup reduction, I've been able to design an alternative algorithm for the Dedekindian HSP i.e. over groups that have only normal subgroups. Recall that the standard Dedekindian HSP algorithm is to use Weak Fourier Sampling, measure a polynomial number of representations <math xmlns="http://www.w3.org/1998/Math/MathML"> <msub> <mi>ρ</mi> <mn>1</mn> </msub> <mo>,</mo> <mo>…</mo> <mo>,</mo> <msub> <mi>ρ</mi> <mi>m</mi> </msub> </math> and then get with high probability the hidden subgroup as the intersection of kernels <math xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>H</mi> <mo>=</mo> <mrow> <munder> <mo>⋂</mo> <mi>i</mi> </munder> <mrow> <mi>Ker</mi> <msub> <mi>ρ</mi> <mi>i</mi> </msub> </mrow> </mrow> </mrow> </math>. When the group is dedekindian, we always have <math xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>H</mi> <mo>⊆</mo> <mrow> <mi>Ker</mi> <msub> <mi>ρ</mi> <mi>i</mi> </msub> </mrow> </mrow> </math>. Hence my alternative algorithm is rather to start by measuring one representation <math xmlns="http://www.w3.org/1998/Math/MathML"> <msub> <mi>ρ</mi> <mn>1</mn> </msub> </math>, move the problem to HSP over <math xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>Ker</mi> <msub> <mi>ρ</mi> <mn>1</mn> </msub> </mrow> </math> and iterate this procedure. I've been able to show that we reach the group <math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>H</mi> </math> after a polynomial number of steps, the idea being that when we measure a non-trivial representation the size of the underlying group becomes at least twice smaller. One difficulty of this approach is to determine the structure of the new group <math xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>Ker</mi> <msub> <mi>ρ</mi> <mi>i</mi> </msub> </mrow> </math> so that we can work on it. However, for the cyclic case this is determination is trivial and for the abelian case I've used the group decomposition algorithm, based on the cyclic HSP. Finally I've two open questions:</p>

<ol>
	<li>Can my algorithm work for the Hamiltonian HSP i.e. over non-abelian dedekindian groups?</li>
	<li>Is my algorithm more efficient than the standard Dedekindian HSP?</li>
</ol>

<p>For the first question, I'm pretty sure that the answer is positive, but I admit that I've not really thought about it. For the second one, it depends on what we mean by more efficient. The decomposition of the kernel seems to increase the time complexity but since we are working on smaller and smaller groups, we decrease the space complexity. However, if we are only considering the numbers of sample, my conjecture is that both algorithms have the same complexity and more precisely yield the same markov process. In order to illustrate this, let's consider the cyclic case <math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>G</mi> <mo>=</mo> <msub> <mi>ℤ</mi> <mn>18</mn> </msub> </math> and <math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>H</mi> <mo>=</mo> <mn>6</mn> <msub> <mi>ℤ</mi> <mn>18</mn> </msub> </math>. The markov chain of the my alternative algorithm is given by the graph below, where the edge labels are of course probabilities and the node labels are the underlying group. We start at <math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>G</mi> <mo>=</mo> <msub> <mi>ℤ</mi> <mn>18</mn> </msub> </math> and want to reach <math xmlns="http://www.w3.org/1998/Math/MathML"> <mi>H</mi> <mo>≅</mo> <msub> <mi>ℤ</mi> <mn>3</mn> </msub> </math>.</p>

<div style="text-align:center;"><svg height="237" width="297" xmlns="http://www.w3.org/2000/svg"> <g class="graph" id="graph1" transform="scale(1 1) rotate(0) translate(4 221.37)"> <polygon fill="none" points="-4,5 -4,-221.37 287,-221.37 287,5 -4,5" stroke="none"></polygon> <!-- 1 --> <g class="node" id="node1">
<title></title>
<ellipse cx="31" cy="-55.3695" fill="none" rx="31.1127" ry="31.1127" stroke="black"></ellipse> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="31" y="-51.7695">Z18</text> </g> <!-- 1&#45;&gt;1 --> <g class="edge" id="edge2">
<title></title>
<path d="M19.7747,-84.5461C19.4067,-95.4193 23.1484,-104.37 31,-104.37 36.1526,-104.37 39.5352,-100.515 41.1479,-94.792" fill="none" stroke="black"></path> <polygon fill="black" points="44.6603,-94.8573 42.2253,-84.5461 37.6986,-94.1253 44.6603,-94.8573" stroke="black"></polygon> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="31" y="-109.77">1/6</text> </g> <!-- 2 --> <g class="node" id="node2">
<title></title>
<ellipse cx="147" cy="-157.37" fill="none" rx="24.2437" ry="24.7487" stroke="black"></ellipse> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="147" y="-153.77">Z9</text> </g> <!-- 1&#45;&gt;2 --> <g class="edge" id="edge4">
<title></title>
<path d="M54.4743,-76.0107C73.7609,-92.9696 101.056,-116.97 121.001,-134.508" fill="none" stroke="black"></path> <polygon fill="black" points="118.698,-137.144 128.519,-141.119 123.321,-131.887 118.698,-137.144" stroke="black"></polygon> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="92" y="-123.77">1/6</text> </g> <!-- 3 --> <g class="node" id="node3">
<title></title>
<ellipse cx="147" cy="-55.3695" fill="none" rx="24.2437" ry="24.7487" stroke="black"></ellipse> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="147" y="-51.7695">Z6</text> </g> <!-- 1&#45;&gt;3 --> <g class="edge" id="edge6">
<title></title>
<path d="M62.0859,-55.3695C77.6104,-55.3695 96.4405,-55.3695 112.42,-55.3695" fill="none" stroke="black"></path> <polygon fill="black" points="112.446,-58.8696 122.446,-55.3695 112.446,-51.8696 112.446,-58.8696" stroke="black"></polygon> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="92" y="-60.7695">1/3</text> </g> <!-- 4 --> <g class="node" id="node4">
<title></title>
<ellipse cx="257" cy="-55.3695" fill="none" rx="24.2437" ry="24.7487" stroke="black"></ellipse> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="257" y="-51.7695">Z3</text> </g> <!-- 1&#45;&gt;4 --> <g class="edge" id="edge8">
<title></title>
<path d="M56.1471,-36.618C73.6197,-24.8032 97.9934,-10.638 122,-4.3695 143.501,1.2448 150.584,1.56235 172,-4.3695 192.99,-10.1835 214.001,-22.714 229.882,-33.8989" fill="none" stroke="black"></path> <polygon fill="black" points="228.002,-36.8597 238.145,-39.9231 232.126,-31.2035 228.002,-36.8597" stroke="black"></polygon> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="147" y="-9.7695">1/3</text> </g> <!-- 2&#45;&gt;2 --> <g class="edge" id="edge10">
<title></title>
<path d="M137.122,-179.41C135.903,-190.011 139.195,-199.37 147,-199.37 152.122,-199.37 155.3,-195.339 156.536,-189.572" fill="none" stroke="black"></path> <polygon fill="black" points="160.039,-189.522 156.878,-179.41 153.043,-189.286 160.039,-189.522" stroke="black"></polygon> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="147" y="-204.77">1/3</text> </g> <!-- 2&#45;&gt;4 --> <g class="edge" id="edge12">
<title></title>
<path d="M165.164,-140.526C183.345,-123.668 211.464,-97.5939 231.798,-78.7383" fill="none" stroke="black"></path> <polygon fill="black" points="234.221,-81.2652 239.174,-71.8993 229.461,-76.1323 234.221,-81.2652" stroke="black"></polygon> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="202" y="-120.77">2/3</text> </g> <!-- 3&#45;&gt;3 --> <g class="edge" id="edge14">
<title></title>
<path d="M137.122,-77.4098C135.903,-88.0111 139.195,-97.3695 147,-97.3695 152.122,-97.3695 155.3,-93.3392 156.536,-87.5722" fill="none" stroke="black"></path> <polygon fill="black" points="160.039,-87.5219 156.878,-77.4098 153.043,-87.2864 160.039,-87.5219" stroke="black"></polygon> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="147" y="-102.77">1/2</text> </g> <!-- 3&#45;&gt;4 --> <g class="edge" id="edge16">
<title></title>
<path d="M171.686,-55.3695C186.547,-55.3695 205.702,-55.3695 222.095,-55.3695" fill="none" stroke="black"></path> <polygon fill="black" points="222.396,-58.8696 232.396,-55.3695 222.396,-51.8696 222.396,-58.8696" stroke="black"></polygon> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="202" y="-60.7695">1/2</text> </g> <!-- 4&#45;&gt;4 --> <g class="edge" id="edge18">
<title></title>
<path d="M247.122,-77.4098C245.903,-88.0111 249.195,-97.3695 257,-97.3695 262.122,-97.3695 265.3,-93.3392 266.536,-87.5722" fill="none" stroke="black"></path> <polygon fill="black" points="270.039,-87.5219 266.878,-77.4098 263.043,-87.2864 270.039,-87.5219" stroke="black"></polygon> <text font-family="Times Roman,serif" font-size="14.00" text-anchor="middle" x="257" y="-102.77">1</text> </g> </g> </svg></div>

<p>One can think that moving to smaller and smaller subgroups will be faster than the standard algorithm which always works on <math xmlns="http://www.w3.org/1998/Math/MathML"> <msub> <mi>ℤ</mi> <mn>18</mn> </msub> </math>. However, it turns out that the markov chain of the standard algorithm is exactly the same. The point being that while it is true that working over <math xmlns="http://www.w3.org/1998/Math/MathML"> <msub> <mi>ℤ</mi> <mn>9</mn> </msub> </math> or <math xmlns="http://www.w3.org/1998/Math/MathML"> <msub> <mi>ℤ</mi> <mn>6</mn> </msub> </math> provides less possibilities of samples (3 and 2 respectively, instead of 6 for <math xmlns="http://www.w3.org/1998/Math/MathML"> <msub> <mi>ℤ</mi> <mn>18</mn> </msub> </math>) the repartition of "good" and "bad" samples is the same and thus we get the same transition probabilities. I guess it would be possible to formalize this for a general cyclic group. The general abelian case seems more difficult, but I'm sure that the same phenomenon can be observed.</p>


{% endraw %}
